{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Proper - torch workflow and operations\n",
    "##### aw f*ck yea,we finally getting into it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow\n",
    " - prep data(turn em into tensors)\n",
    " - pick a model,optimizer and train the model\n",
    " - fit model through the data and make prediction\n",
    " - experiment and improve the model\n",
    " - save and reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu117'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn #neural networks building blocks\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data creation\n",
    "data can be anything message statistic picture audio excelSpreadsheet even a DNA sequence\n",
    "\n",
    "machine learning consist of \n",
    "1)get data into numerical representation \n",
    "2)build a model to study a patern in that numerical rep\n",
    "\n",
    "next is a line of known parameter made with linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create known parameters\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "#create\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start,end,step).unsqueeze(dim=1) #a tensor of data\n",
    "#a tensor. matrix/tensor should be name with uppercase (this one is not yet,but soon nuff)\n",
    "y = weight * X + bias #modified tensor of data\n",
    "#vector should be named with lowercase\n",
    "\n",
    "X[:10],y[:10] #first 10 steps of X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data into test data and training data\n",
    "  **possibly the most important shit in machine learning process**\n",
    "\n",
    "three dataset\n",
    "  - training set   : set to train the model (~60-80%)\n",
    "  - validation set :set to tune model patterns to be more accurate (~10-20%)\n",
    "  - test set       :set to see if the model is ready to run for real (~10-20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making training and testing set split\n",
    "trainSplit = int(0.8 *len(X)) #80% of X\n",
    "Xtrain,ytrain = X[:trainSplit],y[:trainSplit] #train data 80% of X,y\n",
    "Xtest,ytest = X[trainSplit:],y[trainSplit:] #test data 20% of X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xtrain),len(ytrain),len(Xtest),len(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data visualization\n",
    "makes data much easier to understand,trust me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting traing and testing data\n",
    "def predict(trainData = Xtrain,\n",
    "            trainLabel = ytrain,\n",
    "            testData = Xtest,\n",
    "            testLabel = ytest,\n",
    "            predictions = None):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    \n",
    "    # plot training data\n",
    "    plt.scatter(trainData,trainLabel,c = 'b',s = 4 , label = \"training data\")#plot train data color blue size 4\n",
    "    # plot testing data\n",
    "    plt.scatter(testData,testLabel,c = 'r',s = 8 , label = \"testing data\")#plot train data color red size 3\n",
    "    #check for predictions\n",
    "    if predictions is not None:\n",
    "        plt.scatter(testData,predictions,c = 'g',s = 3 , label = \"predictions\")#plot predictions as green size 3\n",
    "        \n",
    "    #show legend label\n",
    "    plt.legend(prop = {\"size\" : 14})\n",
    "#predict()\n",
    "#matplotlib fucking crashes the kernel,even with downgraded library. like wtf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation\n",
    "making the model via linear regression\n",
    "\n",
    "\n",
    "- formula\n",
    "# Y = mX + b\n",
    "### Y is the response (dependent) variable\n",
    "### X is the predictor (independent) variable\n",
    "### m is the estimated slope\n",
    "### b is the estimated intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "#creating linear regression model\n",
    "class LregressionModel(nn.Module):  #nn.module is a building blocks for everything in pytorch\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1,requires_grad=True,dtype = torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1,requires_grad=True,dtype = torch.float))\n",
    "        \n",
    "    def forward(self,x:torch.tensor) ->torch.tensor: # x for input data\n",
    "        return self.weights * x + self.bias #linear regression formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([1.5133], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3708], requires_grad=True)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#model instancing\n",
    "model_0 = LregressionModel()\n",
    "\n",
    "list(model_0.parameters())\n",
    "\n",
    "#Note that results will differs every time because model will be initiated with random values\n",
    "#random weight and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.4704], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0512], requires_grad=True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(36)\n",
    "model_0 = LregressionModel()\n",
    "\n",
    "list(model_0.parameters())\n",
    "#now with seed,its all the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.4704])), ('bias', tensor([-0.0512]))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whole point of deep learning is to use gradient descent,back propagation etc to get theese random weight bias and values toward our ideal value\n",
    "\n",
    "sum:start from random value,and make it able to represent our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "see how well the model do , see how well it predict t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8000],\n",
       "        [0.8200],\n",
       "        [0.8400],\n",
       "        [0.8600],\n",
       "        [0.8800],\n",
       "        [0.9000],\n",
       "        [0.9200],\n",
       "        [0.9400],\n",
       "        [0.9600],\n",
       "        [0.9800]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3251],\n",
       "        [0.3345],\n",
       "        [0.3439],\n",
       "        [0.3533],\n",
       "        [0.3627],\n",
       "        [0.3721],\n",
       "        [0.3815],\n",
       "        [0.3909],\n",
       "        [0.4003],\n",
       "        [0.4097]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    predY = model_0(Xtest)\n",
    "\n",
    "predY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
