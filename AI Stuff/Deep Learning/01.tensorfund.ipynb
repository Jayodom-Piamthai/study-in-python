{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor FUNDAMENTALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dont forgot to load pytorch / tensorflow to the workstation\n",
    "\n",
    "Anaconda: https://www.anaconda.com/download\n",
    "\n",
    "PyTorch: https://pytorch.org/get-started/locally/#anaconda\n",
    "\n",
    "*install pytorch / tensorflow in anaconda then use conda enviroment as kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors fundamental "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vector,scalars,tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSORS\n",
    "\n",
    "#scalars - the magnitude tightens its hold\n",
    "scalarSeven = torch.tensor(7)\n",
    "scalarSeven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get dimension with numpy\n",
    "scalarSeven.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector - this nigga got both magnitude,and direction!\n",
    "vectorSeven = torch.tensor([7,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorSeven.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorSeven.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix - the one,not only one,but the one nonetheless\n",
    "matrixer = torch.tensor([[7,8]\n",
    "                         ,[9,10]])\n",
    "matrixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrixer.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrixer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2],\n",
       "         [ 4,  5],\n",
       "         [ 7,  8],\n",
       "         [ 9, 10]],\n",
       "\n",
       "        [[ 0,  4],\n",
       "         [ 1,  0],\n",
       "         [ 0,  3],\n",
       "         [ 0,  0]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensor - now in 3D!\n",
    "tensory = torch.tensor([[[1,2,]\n",
    "                         ,[4,5]\n",
    "                         ,[7,8]\n",
    "                         ,[9,10]],\n",
    "                        #layer 1 - 1x2x4 data\n",
    "                        [[0,4],\n",
    "                         [1,0],\n",
    "                         [0,3],\n",
    "                         [0,0]]])\n",
    "                        #layer 2 - another layer of 1x2x4 data\n",
    "                        #the lenght of data inside must be the same for each\n",
    "tensory\n",
    "#tensor most of the time wont be made ny hand but my the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensory.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensory.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random tensors\n",
    "neural networks system often starts from a random tensor that has to be adjust to better represent the data\n",
    "\n",
    "for more on torch.rand : https://pytorch.org/docs/stable/generated/torch.rand.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7652, 0.5969, 0.3111],\n",
       "         [0.3737, 0.7062, 0.1248],\n",
       "         [0.8887, 0.0036, 0.1310]],\n",
       "\n",
       "        [[0.4744, 0.3767, 0.9793],\n",
       "         [0.1512, 0.2355, 0.2103],\n",
       "         [0.6362, 0.0462, 0.4454]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rando = torch.rand(2, 3, 3)\n",
    "rando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rando.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rando.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([224, 224, 3]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randImage = torch.rand(size = (224,224,3))\n",
    "randImage.ndim,randImage.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 / 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]]]),\n",
       " tensor([[[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = torch.ones(size = (3,4,5))\n",
    "zero = torch.zeros(size = (3,4,5))\n",
    "zero,one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACE\\AppData\\Local\\Temp\\ipykernel_17936\\2034679965.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  arr = torch.range (0,10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = torch.range (0,10)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  3,  6,  9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51,\n",
       "        54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2 = torch.arange(start = 0 ,end = 100,step = 3)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroed = torch.zeros_like(input=arr2)\n",
    "#make zeros tensor with the shape/size of arr2 - can only do to arrange tensor\n",
    "zeroed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor bit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f32 = torch.tensor([3.0,6.0,9.0]\n",
    "                   ,dtype=None\n",
    "                   ,device=None\n",
    "                   ,requires_grad=False)\n",
    "f32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type conversion\n",
    "f16 = f32.type(torch.float16)\n",
    "f16\n",
    "#the more bit processor can do,the more data it can store/process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f32 * f16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int32 = torch.tensor([3,6,9],dtype=torch.long)\n",
    "int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f32 * int32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor attributes\n",
    "shape - type - device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4516, 0.7032, 0.1744, 0.5644, 0.8546],\n",
      "         [0.9119, 0.1168, 0.2253, 0.1220, 0.1542],\n",
      "         [0.0133, 0.9026, 0.3926, 0.0174, 0.5418],\n",
      "         [0.7144, 0.2920, 0.9482, 0.5167, 0.0207]],\n",
      "\n",
      "        [[0.2766, 0.8517, 0.9568, 0.7355, 0.1181],\n",
      "         [0.6592, 0.1493, 0.5490, 0.7303, 0.2753],\n",
      "         [0.1502, 0.5332, 0.8678, 0.6341, 0.0274],\n",
      "         [0.9489, 0.7998, 0.5904, 0.4246, 0.6853]],\n",
      "\n",
      "        [[0.1952, 0.0820, 0.9149, 0.3596, 0.4206],\n",
      "         [0.1806, 0.2474, 0.5210, 0.2301, 0.5076],\n",
      "         [0.6933, 0.9817, 0.1117, 0.5567, 0.4444],\n",
      "         [0.1558, 0.9099, 0.7524, 0.7523, 0.4325]]])\n",
      "data type is  :torch.float32\n",
      "data shape is : torch.Size([3, 4, 5])\n",
      "device the data is on is : cpu\n"
     ]
    }
   ],
   "source": [
    "randiso = torch.rand(3,4,5)\n",
    "print(randiso)\n",
    "print(f\"data type is  :{randiso.dtype}\")\n",
    "print(f\"data shape is : {randiso.shape}\")\n",
    "print(f\"device the data is on is : {randiso.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor manipulation\n",
    "- Addition\n",
    "- subtraction\n",
    "- multiplication\n",
    "- division\n",
    "- matrix multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([11, 12, 13]),\n",
       " tensor([-11, -10,  -9]),\n",
       " tensor([3, 6, 9]),\n",
       " tensor([0.0833, 0.1667, 0.2500]),\n",
       " tensor([ 5, 10, 15]),\n",
       " tensor([4, 5, 6]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensy = torch.tensor([1,2,3])\n",
    "tensy + 10 ,tensy - 12 ,tensy * 3 , tensy / 12 , torch.mul(tensy,5) ,torch.add(tensy,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matrix multiplication \n",
    "- element wise\n",
    "- matrix multiplication(dot product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "equal : tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "#element wise multiplication ex\n",
    "print(f\"{tensy} * {tensy}\")\n",
    "print(f\"equal : {tensy * tensy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dot product ex\n",
    "torch.matmul(tensy,tensy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## common deep learning problem\n",
    "\n",
    "1) **inner dimension**(the last dimension of the first tensor) must match first dimension of second tensor for it to operate with each other\n",
    "- (3,2) * (3,2) wont work\n",
    "- (2,3) * (3,2) will work\n",
    "- (3,2) * (2,3) will work \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m ein  \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m3\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[0;32m      3\u001b[0m des  \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m torch\u001b[39m.\u001b[39;49mmatmul(ein,ein)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "#example\n",
    "ein  = torch.rand(3,2)\n",
    "des  = torch.rand(2,3)\n",
    "torch.matmul(ein,ein)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6616, 0.6493, 0.3360],\n",
       "         [0.6297, 0.7231, 0.3617],\n",
       "         [0.1627, 0.1259, 0.0692]]),\n",
       " tensor([[0.4950, 0.6652],\n",
       "         [0.6155, 0.9590]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(ein,des) , torch.matmul(des,ein)\n",
    "#(3,2) * (2,3) results in 3x3 tensor while (2,3) * (3,2) results in 3x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. shape error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m ayyy \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m],\n\u001b[0;32m      2\u001b[0m                      [\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m],\n\u001b[0;32m      3\u001b[0m                      [\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m]])\n\u001b[0;32m      4\u001b[0m yooo \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m12\u001b[39m,\u001b[39m13\u001b[39m],\n\u001b[0;32m      5\u001b[0m                      [\u001b[39m23\u001b[39m,\u001b[39m25\u001b[39m],\n\u001b[0;32m      6\u001b[0m                      [\u001b[39m36\u001b[39m,\u001b[39m37\u001b[39m]])\n\u001b[1;32m----> 7\u001b[0m torch\u001b[39m.\u001b[39;49mmm(ayyy,yooo)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "ayyy = torch.tensor([[1,2],\n",
    "                     [3,4],\n",
    "                     [5,6]])\n",
    "yooo = torch.tensor([[12,13],\n",
    "                     [23,25],\n",
    "                     [36,37]])\n",
    "torch.mm(ayyy,yooo) #.mm is matmul,just abrieviated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "due to the shape problem we will ***transpose*** the tensor to make it able to do the mm by switching the axis and dimension of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[12, 23, 36],\n",
       "         [13, 25, 37]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yoyo = yooo.T\n",
    "yoyo,yoyo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 38,  73, 110],\n",
       "        [ 88, 169, 256],\n",
       "        [138, 265, 402]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(ayyy,yoyo) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for mat mul visualization: http://matrixmultiplication.xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor aggregation - finding min/max/mean/sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0,100,10)\n",
    "x,x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x)#torch syntax\n",
    "x.min() #alt syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x)#torch syntax\n",
    "x.max() #alt syntax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mmean(x)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "torch.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.type(torch.float32)\n",
    "torch.mean(y),y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- min max position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor(0))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmax(),x.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor reshaping\n",
    "\n",
    "- reshaping -redefining tensor's shape\n",
    "- view - same tensor from difference view:same memory\n",
    "- stacking - combining tensor on top(vstack) and side (hstack)\n",
    "- unsqueeze - add 1 dimension to tensor\n",
    "- permute - retuen view of input with dimension swaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape\n",
    "x = torch.arange(1.,10.)\n",
    "x,x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 13]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#add 1 dimension\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m reX \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m,\u001b[39m13\u001b[39;49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 13]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "#add 1 dimension\n",
    "reX = x.reshape(1,13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this wont work because the size of the reshape must be the same as original + add 1 dimension at a time to make another dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reX = x.reshape(1,9)\n",
    "reX,reX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change shape\n",
    "z = x.view(1,9)\n",
    "z,z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3., 13.,  5.,  6.,  7.,  8.,  9.]]),\n",
       " tensor([ 1.,  2.,  3., 13.,  5.,  6.,  7.,  8.,  9.]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changing z,and because z is a view of x with same memory , x also change\n",
    "z[:,3] = 13\n",
    "z,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3., 13.,  5.,  6.,  7.,  8.,  9.],\n",
       "        [ 1.,  2.,  3., 13.,  5.,  6.,  7.,  8.,  9.],\n",
       "        [ 1.,  2.,  3., 13.,  5.,  6.,  7.,  8.,  9.],\n",
       "        [ 1.,  2.,  3., 13.,  5.,  6.,  7.,  8.,  9.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stacking tensors\n",
    "stacked = torch.stack([x,x,x,x],dim = 0)\n",
    "stacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 3, 1, 4]), torch.Size([2, 3, 1, 4]), torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#squeezeee out the one-dimension from the tensor\n",
    "x = torch.zeros(2,1,3,1,4)\n",
    "y = x.squeeze(1)#squeeze 1 one dimension dimension layer\n",
    "z = x.squeeze()#squeeze ALL one dimension dimension layer\n",
    "x.size(),y.size(),z.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1, 4])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unsqueeze - add dimension to tensor at specific dimension\n",
    "A = z.unsqueeze(dim = 2)#unsqueeze at the second dimension\n",
    "A.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensor transmute\n",
    "orang = torch.rand(size = (224,224,3))\n",
    "reid = orang.permute(2,0,1)#index 0 shift 2 , index 1 shift 0 , index 2 shift 1\n",
    "reid.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data indexing (chosing data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8],\n",
       "          [ 9, 10, 11, 12]]]),\n",
       " torch.Size([1, 3, 4]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,13).reshape(1,3,4)#reshape into 1x3x3 tensor\n",
    "x,x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 3, 5]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49marange(\u001b[39m1\u001b[39;49m,\u001b[39m10\u001b[39;49m)\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m5\u001b[39;49m)\u001b[39m#reshape into 1x3x5 tensor\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#it will error due to reshape bigger than arange size\u001b[39;00m\n\u001b[0;32m      3\u001b[0m x\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 3, 5]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1,10).reshape(1,3,5)#reshape into 1x3x5 tensor\n",
    "#it will error due to reshape bigger than arange size\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8],\n",
       "         [ 9, 10, 11, 12]]),\n",
       " torch.Size([1, 3, 4]),\n",
       " torch.Size([1, 3, 4]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] #tensor indexing outer dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0] #indexing first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][0] #indexing inner most bracket in the last dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x[\u001b[39m1\u001b[39;49m][\u001b[39m3\u001b[39m][\u001b[39m5\u001b[39m],x[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m][\u001b[39m2\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "x[1][3][5] #will error because the size is out of bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  6, 10]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,:,1] #select all of 0th dimension and 1st dimension and index 1 of 2nd dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy array to tensor\n",
    "import numpy as np\n",
    "import torch\n",
    "arrii = np.arange(1,8)#type int32\n",
    "arr = np.arange(1.0,8.0) #type float 64\n",
    "tensor = torch.from_numpy(arr)\n",
    "arr , tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('int32'), dtype('float64'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrii.dtype,arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, torch.float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1,8).dtype ,torch.arange(1.0,8.0).dtype #torch aramge default type is 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = arr + 1 #plus one to all index\n",
    "arr , tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensor to numpy array\n",
    "tensor = torch.ones(7)\n",
    "np_tensor = tensor.numpy()\n",
    "tensor,np_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plus 1 to tensor\n",
    "tensor = tensor + 1\n",
    "tensor,np_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch reproducibility - taking random out of random\n",
    "this is a gist of how neural network works:\n",
    "\n",
    "start with random number --> tensor operation --> update those random stuff to make it represent more of the data -> repeat -> repeat...\n",
    "\n",
    "fucking apparently computer's \"randomness\" is argubly not truly random\n",
    "\n",
    "so to reduce the randomness in pytorch there come a concept of \"random seed\" which \"flavor\" the randomness\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9272, 0.1133, 0.6179],\n",
       "        [0.7807, 0.0584, 0.4641],\n",
       "        [0.5883, 0.2129, 0.4248]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.rand(3,3) #random a 3x3 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3164, 0.8874, 0.4259, 0.3971],\n",
      "        [0.8050, 0.2036, 0.8320, 0.6108],\n",
      "        [0.9297, 0.9723, 0.2813, 0.7677]])\n",
      "tensor([[0.6233, 0.1892, 0.1603, 0.3003],\n",
      "        [0.5865, 0.0784, 0.9477, 0.0204],\n",
      "        [0.4013, 0.6107, 0.1410, 0.8529]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#create random tensor \n",
    "rngA = torch.rand(3,4)\n",
    "rngB = torch.rand(3,4)\n",
    "print(rngA)\n",
    "print(rngB)\n",
    "print(rngA == rngB)\n",
    "#its very likely that every index of rng a and b will not be the same due to the randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3659, 0.7025, 0.3104, 0.0097],\n",
      "        [0.6577, 0.1947, 0.9506, 0.6887],\n",
      "        [0.8174, 0.7575, 0.7492, 0.6874]])\n",
      "tensor([[0.3659, 0.7025, 0.3104, 0.0097],\n",
      "        [0.6577, 0.1947, 0.9506, 0.6887],\n",
      "        [0.8174, 0.7575, 0.7492, 0.6874]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "randomSeed = 22\n",
    "torch.manual_seed(randomSeed)#set the manual seed before random round 1\n",
    "randomTensor = torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(randomSeed)#set the manual seed before random round 1\n",
    "randomTensorB = torch.rand(3,4)\n",
    "\n",
    "print(randomTensor)\n",
    "print(randomTensorB)\n",
    "print(randomTensor == randomTensorB)\n",
    "#same seed,same results\n",
    "#results may not be the same with different CPU/GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more on randomness at: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "https://en.wikipedia.org/wiki/Random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running tensor/PyTorch on GPU\n",
    "gpu make number computation easier and faster thanks to CUDA + nvidia hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- method 1: use google collab for free gpu processing\n",
    "- method 2:use your own GPU\n",
    "- method 3:use cloud computing (ex: azure AWS GCP) allow computer renting\n",
    "\n",
    "for 2 and 3 pytorch +gpu driver take a while to set up CUDA\n",
    "- for torch setup https://pytorch.org/get-started/locally/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 12 16:20:21 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 537.13                 Driver Version: 537.13       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1060 6GB  WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   48C    P8               9W / 120W |   2538MiB /  6144MiB |      6%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A       288    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      1336    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A      1472    C+G   ...cks-services\\BlueStacksServices.exe    N/A      |\n",
      "|    0   N/A  N/A      3480    C+G   ...\\Local\\Figma\\app-116.12.2\\Figma.exe    N/A      |\n",
      "|    0   N/A  N/A      3564    C+G   ...on\\116.0.1938.76\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A      5900    C+G   ...on\\116.0.1938.76\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A      5904    C+G   ...ne\\Binaries\\Win64\\EpicWebHelper.exe    N/A      |\n",
      "|    0   N/A  N/A      7120    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      8156    C+G   ...inaries\\Win64\\EpicGamesLauncher.exe    N/A      |\n",
      "|    0   N/A  N/A      8608    C+G   ...a\\Local\\Programs\\Opera GX\\opera.exe    N/A      |\n",
      "|    0   N/A  N/A      9168    C+G   ...al\\Discord\\app-1.0.9017\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A      9396    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9496    C+G   ...l\\Microsoft\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A      9636    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11096    C+G   ...on\\116.0.1938.76\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     12604    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     13208    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14196    C+G   ...on\\wallpaper_engine\\wallpaper32.exe    N/A      |\n",
      "|    0   N/A  N/A     14932    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     15172    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     15616    C+G   ...a\\Local\\slack\\app-4.33.90\\slack.exe    N/A      |\n",
      "|    0   N/A  N/A     17208    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     18012    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     18484    C+G   ...gin\\LineCall\\1.0.0.692\\LineCall.exe    N/A      |\n",
      "|    0   N/A  N/A     19592    C+G   ...AppData\\Roaming\\Spotify\\Spotify.exe    N/A      |\n",
      "|    0   N/A  N/A     19980    C+G   ...ata\\Local\\LINE\\bin\\current\\LINE.exe    N/A      |\n",
      "|    0   N/A  N/A     19996    C+G   ...l\\Microsoft\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     20864    C+G   ...64__v826wp6bftszj\\TranslucentTB.exe    N/A      |\n",
      "|    0   N/A  N/A     21184    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     23716    C+G   ...ience\\NVIDIA GeForce Experience.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#checking gpu\n",
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check gpu access with pytorch\n",
    "import torch \n",
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
